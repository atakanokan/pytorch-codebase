{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "num_epochs = 5\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# MNIST Dataset\n",
    "train_dataset = dsets.MNIST(root='./data/',\n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./data/',\n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())\n",
    "\n",
    "# Data Loader (Input Pipeline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CNN Model (2 conv layer)\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.fc = nn.Linear(7*7*32, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "        \n",
    "cnn = CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Iter [100/600] Loss: 0.1003\n",
      "Epoch [1/5], Iter [200/600] Loss: 0.0721\n",
      "Epoch [1/5], Iter [300/600] Loss: 0.0879\n",
      "Epoch [1/5], Iter [400/600] Loss: 0.0343\n",
      "Epoch [1/5], Iter [500/600] Loss: 0.1069\n",
      "Epoch [1/5], Iter [600/600] Loss: 0.0390\n",
      "Epoch [2/5], Iter [100/600] Loss: 0.0055\n",
      "Epoch [2/5], Iter [200/600] Loss: 0.1176\n",
      "Epoch [2/5], Iter [300/600] Loss: 0.0452\n",
      "Epoch [2/5], Iter [400/600] Loss: 0.0244\n",
      "Epoch [2/5], Iter [500/600] Loss: 0.0201\n",
      "Epoch [2/5], Iter [600/600] Loss: 0.0170\n",
      "Epoch [3/5], Iter [100/600] Loss: 0.0521\n",
      "Epoch [3/5], Iter [200/600] Loss: 0.0300\n",
      "Epoch [3/5], Iter [300/600] Loss: 0.0210\n",
      "Epoch [3/5], Iter [400/600] Loss: 0.0479\n",
      "Epoch [3/5], Iter [500/600] Loss: 0.0365\n",
      "Epoch [3/5], Iter [600/600] Loss: 0.0029\n",
      "Epoch [4/5], Iter [100/600] Loss: 0.0424\n",
      "Epoch [4/5], Iter [200/600] Loss: 0.0476\n",
      "Epoch [4/5], Iter [300/600] Loss: 0.0477\n",
      "Epoch [4/5], Iter [400/600] Loss: 0.0169\n",
      "Epoch [4/5], Iter [500/600] Loss: 0.0101\n",
      "Epoch [4/5], Iter [600/600] Loss: 0.0721\n",
      "Epoch [5/5], Iter [100/600] Loss: 0.0019\n",
      "Epoch [5/5], Iter [200/600] Loss: 0.0228\n",
      "Epoch [5/5], Iter [300/600] Loss: 0.0074\n",
      "Epoch [5/5], Iter [400/600] Loss: 0.0319\n",
      "Epoch [5/5], Iter [500/600] Loss: 0.0259\n",
      "Epoch [5/5], Iter [600/600] Loss: 0.0141\n"
     ]
    }
   ],
   "source": [
    "# Train the Model\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = Variable(images)\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = cnn(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [%d/%d], Iter [%d/%d] Loss: %.4f' \n",
    "                   %(epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 10000 test images: 99 %\n"
     ]
    }
   ],
   "source": [
    "# Test the Model\n",
    "cnn.eval()  # Change model to 'eval' mode (BN uses moving mean/var).\n",
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in test_loader:\n",
    "    images = Variable(images)\n",
    "    outputs = cnn(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Test Accuracy of the model on the 10000 test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the Trained Model\n",
    "torch.save(cnn.state_dict(), 'cnn.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('layer1.0.weight', \n",
       "              (0 ,0 ,.,.) = \n",
       "                0.0192 -0.2377 -0.0259 -0.0034  0.2317\n",
       "               -0.1871 -0.1309  0.1481 -0.0222  0.1515\n",
       "               -0.1007 -0.1540 -0.2077 -0.0076 -0.1569\n",
       "                0.1484 -0.0424 -0.0330 -0.0250 -0.2016\n",
       "                0.0209 -0.0152 -0.0557 -0.1260  0.1461\n",
       "              \n",
       "              (1 ,0 ,.,.) = \n",
       "                0.1470 -0.0353  0.0420  0.0920 -0.2643\n",
       "               -0.0345 -0.0829  0.2217 -0.0669 -0.2647\n",
       "                0.0042 -0.0952  0.1670  0.1553 -0.0742\n",
       "               -0.1442 -0.0184 -0.1295  0.2014 -0.0783\n",
       "               -0.1256  0.0406 -0.0267 -0.0253  0.1131\n",
       "              \n",
       "              (2 ,0 ,.,.) = \n",
       "               -0.0609 -0.0292 -0.1582  0.0756 -0.1383\n",
       "               -0.2166 -0.0005 -0.1600  0.1455 -0.0943\n",
       "               -0.0515 -0.1928  0.1504  0.0795 -0.1611\n",
       "               -0.1230 -0.1065  0.2082 -0.0167 -0.0891\n",
       "               -0.2524  0.0246  0.2278 -0.1187 -0.0322\n",
       "              \n",
       "              (3 ,0 ,.,.) = \n",
       "               -0.1075  0.0056  0.1159  0.0700 -0.0206\n",
       "                0.1741 -0.0560  0.0883  0.1199  0.2548\n",
       "               -0.1100 -0.0402  0.1888  0.0376 -0.0769\n",
       "                0.0551 -0.1446 -0.1836 -0.0823  0.1247\n",
       "               -0.0952 -0.0069 -0.2431 -0.2081 -0.2336\n",
       "              \n",
       "              (4 ,0 ,.,.) = \n",
       "                0.1039  0.0114  0.1316 -0.0706 -0.1447\n",
       "               -0.0452  0.0358 -0.2252 -0.2722  0.0003\n",
       "                0.0470 -0.2183 -0.2299  0.0696  0.1636\n",
       "               -0.1697 -0.2458  0.1191 -0.0216  0.0444\n",
       "               -0.2361 -0.0227  0.0348 -0.0906  0.1907\n",
       "              \n",
       "              (5 ,0 ,.,.) = \n",
       "               -0.1178  0.1567  0.0274  0.1713 -0.1190\n",
       "               -0.1321  0.0784 -0.0076 -0.1164 -0.0997\n",
       "               -0.2298 -0.0217 -0.0204  0.2361 -0.0402\n",
       "               -0.2288  0.1538  0.1183 -0.0463  0.0592\n",
       "               -0.2776  0.0969  0.1393  0.1196 -0.1811\n",
       "              \n",
       "              (6 ,0 ,.,.) = \n",
       "                0.1163 -0.2422 -0.0619 -0.1535 -0.0247\n",
       "                0.1507 -0.1268 -0.0517  0.0727 -0.0110\n",
       "                0.1180  0.1979  0.0398 -0.2106 -0.0314\n",
       "               -0.0523  0.1277  0.1239 -0.1067 -0.0367\n",
       "               -0.0146 -0.1377  0.1711  0.1174 -0.1395\n",
       "              \n",
       "              (7 ,0 ,.,.) = \n",
       "                0.1058  0.0637  0.0417 -0.1238  0.1674\n",
       "               -0.2158  0.0461 -0.2023  0.0795 -0.2023\n",
       "               -0.0768 -0.1555  0.0378 -0.1073 -0.0868\n",
       "                0.0858  0.0790  0.1976  0.1719 -0.0841\n",
       "                0.1242 -0.0935 -0.2344  0.0073 -0.1040\n",
       "              \n",
       "              (8 ,0 ,.,.) = \n",
       "                0.2110  0.0270  0.0081  0.0654 -0.1893\n",
       "                0.0723 -0.0490  0.1110 -0.2306 -0.1046\n",
       "                0.0098 -0.0116 -0.1806 -0.2253 -0.0013\n",
       "               -0.1584 -0.1468 -0.0826 -0.0865  0.2344\n",
       "               -0.1227 -0.1007  0.0318  0.0332 -0.0799\n",
       "              \n",
       "              (9 ,0 ,.,.) = \n",
       "                0.0995 -0.1629  0.1323  0.0416  0.0810\n",
       "               -0.1213  0.0459  0.0728 -0.1218  0.0536\n",
       "               -0.2245  0.1718  0.1711  0.0319 -0.1430\n",
       "               -0.1190  0.3042 -0.0190 -0.2002 -0.1165\n",
       "                0.0975  0.1443 -0.1404 -0.0180 -0.0636\n",
       "              \n",
       "              (10,0 ,.,.) = \n",
       "               -0.2210  0.1146  0.1045  0.0661  0.0878\n",
       "               -0.1847  0.1696 -0.0340 -0.0509 -0.0465\n",
       "               -0.2254  0.1356  0.0671  0.0397  0.1683\n",
       "               -0.2643  0.0525 -0.0469 -0.0955  0.0158\n",
       "               -0.1573 -0.1013  0.0683 -0.1027 -0.0178\n",
       "              \n",
       "              (11,0 ,.,.) = \n",
       "               -0.2886 -0.0344 -0.1086  0.0252 -0.0499\n",
       "               -0.0777 -0.1231 -0.2353 -0.1341 -0.0108\n",
       "                0.1240  0.1053  0.0056 -0.0826 -0.2364\n",
       "               -0.0150  0.0011 -0.0154  0.0353  0.1063\n",
       "                0.0177  0.0005  0.1072  0.0240  0.1287\n",
       "              \n",
       "              (12,0 ,.,.) = \n",
       "                0.1684  0.1027  0.1531 -0.0203  0.0788\n",
       "                0.0413 -0.1430  0.2045  0.1781  0.1613\n",
       "               -0.2762  0.0020 -0.0908  0.1412  0.0583\n",
       "                0.0248  0.0435 -0.0376  0.0199  0.0830\n",
       "                0.1617 -0.1506  0.0939  0.1826  0.0658\n",
       "              \n",
       "              (13,0 ,.,.) = \n",
       "                0.1583  0.0688  0.0266  0.2124  0.0290\n",
       "               -0.0242  0.2622 -0.0134  0.0528  0.2341\n",
       "               -0.2460 -0.1667 -0.0662 -0.0747 -0.1440\n",
       "                0.0702 -0.0579 -0.1538 -0.0549 -0.0673\n",
       "               -0.0930 -0.1013 -0.0284  0.0024 -0.0389\n",
       "              \n",
       "              (14,0 ,.,.) = \n",
       "                0.1217 -0.0115  0.1501 -0.1104 -0.1353\n",
       "                0.1279 -0.1407 -0.2295 -0.1143  0.0154\n",
       "               -0.1416 -0.1502  0.0605  0.1219  0.1124\n",
       "               -0.2161  0.0305  0.1225  0.0962  0.1517\n",
       "                0.1503  0.1306  0.0539 -0.1015 -0.2095\n",
       "              \n",
       "              (15,0 ,.,.) = \n",
       "               -0.1866  0.1517 -0.0228 -0.0587 -0.1908\n",
       "               -0.0613 -0.0568  0.1862 -0.0723 -0.2200\n",
       "                0.0305 -0.0291  0.0546 -0.0333 -0.2279\n",
       "                0.0505  0.0498  0.1142 -0.1670 -0.1790\n",
       "                0.2004  0.0250  0.0495 -0.1810  0.0215\n",
       "              [torch.FloatTensor of size 16x1x5x5]), ('layer1.0.bias', \n",
       "               0.0408\n",
       "              -0.0223\n",
       "              -0.0489\n",
       "              -0.0982\n",
       "              -0.0708\n",
       "               0.0410\n",
       "               0.1406\n",
       "              -0.1951\n",
       "              -0.1903\n",
       "               0.1437\n",
       "               0.0672\n",
       "               0.0469\n",
       "              -0.1157\n",
       "               0.1926\n",
       "               0.0042\n",
       "               0.0873\n",
       "              [torch.FloatTensor of size 16]), ('layer1.1.weight', \n",
       "               0.9139\n",
       "               0.3314\n",
       "               0.7428\n",
       "               0.2069\n",
       "               0.7735\n",
       "               0.1790\n",
       "               0.2770\n",
       "               0.4159\n",
       "               0.5147\n",
       "               0.3288\n",
       "               0.3245\n",
       "               0.7373\n",
       "               0.3778\n",
       "               0.2643\n",
       "               0.5260\n",
       "               0.5704\n",
       "              [torch.FloatTensor of size 16]), ('layer1.1.bias', \n",
       "              -0.2359\n",
       "              -0.2214\n",
       "              -0.2431\n",
       "              -0.0106\n",
       "              -0.1383\n",
       "              -0.0990\n",
       "              -0.1757\n",
       "              -0.1033\n",
       "              -0.1087\n",
       "              -0.2240\n",
       "              -0.0536\n",
       "              -0.1390\n",
       "              -0.2277\n",
       "              -0.0642\n",
       "              -0.1245\n",
       "              -0.1895\n",
       "              [torch.FloatTensor of size 16]), ('layer1.1.running_mean', \n",
       "              -0.0730\n",
       "              -0.0633\n",
       "              -0.1950\n",
       "              -0.1484\n",
       "              -0.2050\n",
       "              -0.0003\n",
       "               0.1202\n",
       "              -0.2576\n",
       "              -0.3175\n",
       "               0.1398\n",
       "               0.0068\n",
       "              -0.0498\n",
       "               0.0450\n",
       "               0.1631\n",
       "              -0.0092\n",
       "              -0.0098\n",
       "              [torch.FloatTensor of size 16]), ('layer1.1.running_var', \n",
       "               0.0622\n",
       "               0.0195\n",
       "               0.0690\n",
       "               0.0561\n",
       "               0.1069\n",
       "               0.0321\n",
       "               0.0195\n",
       "               0.0181\n",
       "               0.0887\n",
       "               0.0288\n",
       "               0.0375\n",
       "               0.0559\n",
       "               0.0821\n",
       "               0.0443\n",
       "               0.0237\n",
       "               0.0721\n",
       "              [torch.FloatTensor of size 16]), ('layer2.0.weight', \n",
       "              (0 ,0 ,.,.) = \n",
       "               -2.7523e-02  2.7417e-02 -3.8203e-02 -6.5586e-02 -6.8830e-04\n",
       "               -5.5700e-03 -6.4781e-02 -5.2959e-02  2.7374e-02  2.7301e-02\n",
       "               -2.2260e-02 -6.3402e-03  2.8657e-03  1.3077e-01  6.1806e-02\n",
       "               -1.1351e-01  2.0275e-02  3.7137e-02  8.4092e-02  8.6718e-02\n",
       "               -1.0594e-01 -6.2845e-03 -3.3774e-02 -3.1120e-02  1.1760e-01\n",
       "              \n",
       "              (0 ,1 ,.,.) = \n",
       "               -8.1425e-02  1.1664e-02  1.1284e-03 -5.1273e-02 -5.7599e-02\n",
       "                2.4385e-03  1.5902e-02 -3.0797e-02 -6.8727e-03  4.9758e-02\n",
       "               -5.3393e-02 -2.6093e-02 -1.2417e-02  1.1095e-02  8.8239e-02\n",
       "               -2.8176e-02 -1.4731e-02 -2.7146e-02  4.4373e-02  7.8934e-02\n",
       "                1.6235e-02  2.5918e-02  5.5626e-02  1.0618e-01  8.6602e-02\n",
       "              \n",
       "              (0 ,2 ,.,.) = \n",
       "                5.1400e-02  3.2147e-02 -3.7384e-03  2.9597e-02 -4.7015e-02\n",
       "                7.3060e-02  1.0864e-01  8.4726e-03  1.8700e-03 -1.9194e-02\n",
       "                1.3670e-01  9.6825e-02  1.2794e-02  5.0134e-02  4.6626e-02\n",
       "                7.6720e-02 -5.3210e-02 -6.0704e-02  4.3990e-02 -1.6945e-02\n",
       "                1.0259e-01  4.0621e-02 -3.2358e-02 -6.2098e-02 -5.5434e-02\n",
       "                 ...\n",
       "              \n",
       "              (0 ,13,.,.) = \n",
       "                8.4614e-02  8.3579e-02 -2.8620e-02  5.7424e-02  1.4607e-02\n",
       "               -9.7054e-03 -5.4190e-02  3.1532e-02  1.7735e-02  3.7686e-03\n",
       "               -1.2265e-01 -3.4851e-02 -4.5805e-02  4.5231e-02 -2.7980e-02\n",
       "                6.2067e-03 -2.3029e-02 -3.0241e-02 -3.0758e-02  2.7135e-02\n",
       "               -8.4067e-02 -4.5904e-02  3.5262e-02  6.1184e-03  4.8252e-02\n",
       "              \n",
       "              (0 ,14,.,.) = \n",
       "               -2.0329e-02  3.6842e-02 -2.9881e-02 -1.1835e-02 -2.0785e-02\n",
       "                4.2753e-03 -1.0443e-02 -2.8577e-02 -5.0272e-02 -9.2335e-02\n",
       "                1.6577e-02 -2.3231e-02  5.4888e-03 -2.6978e-02 -3.0069e-02\n",
       "                1.1157e-02 -2.3705e-02 -4.3584e-02  1.2165e-02  5.8873e-02\n",
       "               -8.8904e-03 -3.2368e-02  1.6070e-03  7.4873e-03 -9.0938e-04\n",
       "              \n",
       "              (0 ,15,.,.) = \n",
       "               -3.4449e-02  3.2019e-02 -2.5604e-02 -5.7886e-03 -2.6660e-02\n",
       "                2.4608e-02  1.0793e-01  5.1416e-02 -5.8917e-02  8.1461e-03\n",
       "               -2.3634e-02  1.2133e-01  2.7084e-02 -1.9030e-03  1.0056e-01\n",
       "                5.7961e-02  6.2935e-02 -3.3235e-02 -3.1849e-02  5.7881e-02\n",
       "                4.5512e-02  2.7931e-02 -3.9811e-02 -6.2493e-03  3.6623e-02\n",
       "                   ⋮ \n",
       "              \n",
       "              (1 ,0 ,.,.) = \n",
       "               -8.3794e-03  7.0803e-02  1.8235e-02 -4.9211e-02 -2.0313e-02\n",
       "                2.9621e-02 -2.2146e-03  1.9172e-02  3.1414e-02  2.1547e-02\n",
       "               -5.4559e-02 -9.1258e-02  5.0117e-02  1.6094e-03 -3.0704e-02\n",
       "               -9.9918e-02  1.1113e-02  5.8278e-02 -7.3809e-02 -1.4843e-02\n",
       "                2.9069e-02 -1.7778e-02 -1.9747e-02 -1.1966e-01 -7.6843e-02\n",
       "              \n",
       "              (1 ,1 ,.,.) = \n",
       "                8.2379e-02  1.3500e-02 -5.7514e-02 -9.5490e-02 -1.5985e-01\n",
       "                1.7504e-02  1.8701e-03 -5.0168e-02 -1.5765e-02 -3.2824e-02\n",
       "               -2.5756e-02 -9.6052e-03 -3.3256e-02 -5.7236e-03 -1.0176e-01\n",
       "               -6.2302e-03  1.9450e-02  2.7260e-02 -4.4004e-02 -7.2620e-02\n",
       "                2.7523e-02  2.9373e-02 -5.6212e-02 -8.9306e-02 -8.2801e-02\n",
       "              \n",
       "              (1 ,2 ,.,.) = \n",
       "                7.0397e-02  4.6164e-02 -2.4933e-02  3.9291e-03 -4.3730e-02\n",
       "                6.4756e-02  9.3372e-02  8.6255e-02  2.2205e-02  9.3267e-03\n",
       "                4.7236e-02  1.1440e-01  2.3072e-02 -6.6811e-03 -3.2635e-03\n",
       "                1.3709e-02 -1.6979e-02 -8.1913e-02 -4.9835e-02 -2.0662e-02\n",
       "                1.3534e-01  7.5136e-02  2.3619e-02  7.3605e-02  5.7253e-02\n",
       "                 ...\n",
       "              \n",
       "              (1 ,13,.,.) = \n",
       "                3.7403e-02  5.8236e-02  7.3135e-02 -3.3394e-02  6.1642e-02\n",
       "                3.0520e-02  1.3136e-01  5.2596e-03 -1.5199e-02  3.4977e-02\n",
       "               -2.8941e-02  7.8140e-02  1.2627e-02  4.2292e-02  5.9950e-02\n",
       "               -6.4437e-02 -8.6191e-03  7.7147e-02  1.1352e-01  1.1925e-01\n",
       "               -5.0003e-02 -4.8762e-02 -3.1070e-02  4.4818e-02 -7.0101e-03\n",
       "              \n",
       "              (1 ,14,.,.) = \n",
       "                2.5166e-02 -4.4980e-02 -1.1490e-01 -1.3042e-01 -3.1482e-02\n",
       "                7.2206e-03  7.4354e-03 -1.3440e-02 -2.4513e-02  2.6858e-02\n",
       "               -7.7682e-02 -6.2880e-02  2.1988e-02  1.9528e-02  9.5852e-02\n",
       "               -1.2622e-01 -1.2183e-01 -4.2649e-02 -2.5990e-02  4.4120e-02\n",
       "               -7.3677e-02 -6.3201e-02 -5.4433e-02 -2.0566e-02 -1.0936e-01\n",
       "              \n",
       "              (1 ,15,.,.) = \n",
       "               -8.4414e-02  4.2043e-02  1.9915e-03  2.3797e-02  1.9950e-02\n",
       "                1.0316e-02  3.9170e-02  4.4307e-02 -3.1545e-02 -3.1701e-04\n",
       "               -2.0130e-02  1.7265e-02  7.3782e-02  6.2219e-02  1.0693e-02\n",
       "                5.0756e-02 -3.2280e-02 -2.9189e-02 -4.0491e-02 -4.3268e-02\n",
       "                5.3516e-02  5.0504e-02 -3.5473e-02 -1.7574e-02  1.0236e-02\n",
       "                   ⋮ \n",
       "              \n",
       "              (2 ,0 ,.,.) = \n",
       "                2.7872e-02  8.2584e-02 -1.7339e-02  4.7086e-03  8.2055e-02\n",
       "                1.4669e-01  6.7732e-02 -1.2518e-01 -5.1960e-02  1.8943e-02\n",
       "                8.4841e-02 -1.7176e-02  9.1894e-03  3.6986e-02  7.3667e-02\n",
       "               -1.1590e-02 -2.6798e-03  1.1791e-02  3.6109e-02  4.5492e-02\n",
       "               -9.1374e-02 -9.5508e-06  1.4738e-02  5.0518e-02  7.0042e-03\n",
       "              \n",
       "              (2 ,1 ,.,.) = \n",
       "                4.2964e-02 -2.4712e-02 -1.3726e-02 -2.8692e-02  8.6908e-03\n",
       "                8.1974e-03 -6.0508e-02 -4.3818e-02  3.8236e-02  3.0497e-02\n",
       "               -4.7774e-02 -3.5055e-02 -2.0080e-02  4.6492e-02 -7.8521e-02\n",
       "               -6.9842e-02 -5.2165e-02  5.3956e-02 -1.6412e-02  7.0166e-02\n",
       "               -5.1698e-02  1.2912e-02 -5.5224e-03  3.1312e-02 -4.0325e-02\n",
       "              \n",
       "              (2 ,2 ,.,.) = \n",
       "               -3.7752e-02 -2.3969e-02 -2.4711e-02 -2.7462e-02 -5.7516e-02\n",
       "                2.9476e-02 -7.6666e-02  3.3613e-02 -4.4429e-02 -9.4652e-02\n",
       "                3.3298e-02 -4.1430e-02  5.0892e-02  6.1483e-02 -4.3366e-02\n",
       "                4.2388e-02  6.4841e-03  8.2735e-02  9.3147e-02 -2.5095e-03\n",
       "               -9.1467e-02  7.3024e-03  4.8176e-02  8.0436e-02  1.7284e-02\n",
       "                 ...\n",
       "              \n",
       "              (2 ,13,.,.) = \n",
       "                1.9516e-01  2.1183e-01  9.9964e-02  1.0826e-01  7.0172e-02\n",
       "                1.3535e-01  8.0414e-02  8.3431e-02 -4.1855e-02 -2.6529e-02\n",
       "               -1.4012e-02  7.4345e-02  7.6975e-02  1.2972e-02  8.2588e-02\n",
       "               -4.1057e-02 -6.0667e-02  2.9892e-02  1.3845e-02 -9.0061e-03\n",
       "                6.7848e-02 -6.6906e-02 -1.1968e-02  1.0883e-02 -8.4751e-02\n",
       "              \n",
       "              (2 ,14,.,.) = \n",
       "               -1.1262e-01  2.0043e-02 -9.1218e-03  1.3560e-02 -3.1152e-02\n",
       "               -7.1460e-03  3.4586e-02  6.7947e-02  1.0018e-02 -1.4307e-02\n",
       "                2.3271e-03 -1.5808e-02  2.0754e-02  4.2787e-02 -4.4294e-02\n",
       "                6.5773e-02 -4.2861e-02 -3.1816e-02 -1.5697e-02 -5.3010e-02\n",
       "                7.3579e-03 -4.5789e-02 -8.5776e-03 -3.4072e-02 -5.6967e-02\n",
       "              \n",
       "              (2 ,15,.,.) = \n",
       "               -1.2233e-02 -3.4367e-02  2.0563e-02 -2.0355e-02  7.5729e-02\n",
       "               -1.2889e-02  2.0813e-02 -3.4185e-02  3.1291e-02  8.0986e-02\n",
       "               -9.3983e-03  6.1639e-02  4.7732e-02  3.4192e-02  7.7449e-02\n",
       "                9.9723e-02  6.2988e-04  2.9698e-02  1.6924e-02  2.5794e-03\n",
       "                3.1393e-02 -4.6944e-03  4.1253e-02  2.6363e-04  2.9884e-02\n",
       "              ...   \n",
       "                   ⋮ \n",
       "              \n",
       "              (29,0 ,.,.) = \n",
       "               -3.3001e-02 -8.6046e-02 -4.3692e-02 -7.5948e-02 -1.4352e-02\n",
       "               -8.5997e-02 -2.5061e-02  8.3010e-02  6.5799e-02 -8.5974e-03\n",
       "                1.0790e-02  1.5493e-03  6.6510e-02  8.6912e-04 -7.4492e-03\n",
       "               -6.0876e-04 -9.7499e-02 -7.3163e-02 -5.6352e-02 -3.2669e-02\n",
       "                1.9586e-02 -6.4653e-02 -1.4119e-02 -8.0001e-02  5.8965e-03\n",
       "              \n",
       "              (29,1 ,.,.) = \n",
       "               -2.6062e-02 -6.7361e-02 -9.5180e-03 -2.2383e-02 -1.3716e-02\n",
       "               -4.4108e-02 -1.2792e-02  2.9348e-02  4.9453e-02  3.2637e-02\n",
       "               -1.1058e-02 -2.6445e-02  1.6257e-02  1.1399e-02  2.1914e-02\n",
       "                7.0855e-02 -2.6393e-03 -5.2980e-02 -3.2412e-03  6.9858e-03\n",
       "               -1.2666e-04  9.0871e-03  3.0364e-02 -3.4017e-03 -4.6953e-02\n",
       "              \n",
       "              (29,2 ,.,.) = \n",
       "                3.2520e-02  4.7180e-02  2.6100e-02  7.5422e-02  2.4957e-02\n",
       "                6.7744e-02  1.1528e-01  2.8952e-02 -4.9146e-02 -2.4496e-02\n",
       "                5.1516e-02  6.3937e-02  2.6045e-02 -3.0760e-02 -5.6701e-02\n",
       "               -5.4134e-02 -2.0674e-02 -3.8054e-02  2.5325e-02  6.0311e-03\n",
       "                1.2197e-02 -4.1826e-02  2.4089e-02  3.9070e-02 -2.3757e-02\n",
       "                 ...\n",
       "              \n",
       "              (29,13,.,.) = \n",
       "               -9.6093e-02 -2.4987e-02 -9.3007e-02 -5.2060e-02  1.3355e-03\n",
       "               -8.0480e-02 -1.8780e-02  5.6610e-02  3.4640e-02  2.8907e-02\n",
       "                2.1071e-03  1.1306e-01  8.9778e-03 -5.3001e-02 -4.2685e-02\n",
       "                9.8409e-02  3.2825e-02  3.2393e-02 -1.8160e-02 -1.6697e-02\n",
       "                2.0793e-01  1.1034e-01  6.7648e-02 -3.0165e-02  1.3044e-02\n",
       "              \n",
       "              (29,14,.,.) = \n",
       "                3.1918e-02 -2.4228e-02  6.2103e-02  1.4176e-01  3.0123e-02\n",
       "                7.5352e-03 -1.0061e-01 -4.3641e-02  5.1208e-02 -3.9044e-02\n",
       "               -1.6678e-02  4.1542e-02  1.2602e-02 -3.7871e-02 -6.0621e-02\n",
       "               -2.8609e-02  5.2531e-02  8.8862e-02  2.5561e-02 -8.7427e-03\n",
       "               -6.5857e-03 -2.7636e-02  6.8140e-02 -1.7332e-02  1.5039e-02\n",
       "              \n",
       "              (29,15,.,.) = \n",
       "                3.1394e-03  5.5274e-02  4.3878e-02 -1.1483e-02 -3.5070e-02\n",
       "               -1.5661e-02  2.4628e-03 -2.4038e-02  2.4421e-02  1.9436e-02\n",
       "                1.0774e-02  2.6674e-02  7.6716e-02  6.0001e-02  6.1365e-02\n",
       "               -4.1167e-02 -2.8373e-02  2.1561e-02  6.5278e-02 -4.2064e-03\n",
       "               -3.4077e-02 -9.3033e-02 -7.5035e-02 -1.5263e-02 -5.4061e-02\n",
       "                   ⋮ \n",
       "              \n",
       "              (30,0 ,.,.) = \n",
       "                7.5396e-02  2.7943e-03 -1.8037e-02  6.6425e-03  3.3379e-02\n",
       "               -2.2842e-03  3.9905e-02  3.5053e-02  8.1705e-02  4.6426e-03\n",
       "                3.6669e-02  6.2755e-02  3.2811e-02 -8.7735e-03  8.0578e-03\n",
       "               -4.2985e-02  1.2610e-03  1.4791e-02  1.2670e-03  1.7415e-02\n",
       "                1.3384e-02 -1.5640e-02 -4.2849e-02  4.2775e-03 -4.1116e-02\n",
       "              \n",
       "              (30,1 ,.,.) = \n",
       "                4.9364e-02  3.3207e-02  5.1608e-02 -1.5486e-02  1.0949e-01\n",
       "                6.6198e-02  2.1736e-01  1.0519e-01 -6.5028e-03  9.0386e-02\n",
       "                1.2511e-02  4.1853e-02  5.2237e-02 -3.3746e-02  1.1968e-02\n",
       "               -4.5357e-02 -7.6056e-02  2.5539e-02 -1.7532e-03  1.0044e-02\n",
       "               -8.1557e-02 -1.9558e-02  1.0314e-01  2.3243e-02  9.4962e-03\n",
       "              \n",
       "              (30,2 ,.,.) = \n",
       "               -5.5681e-02 -7.4794e-02  4.2310e-02 -2.8489e-02  8.9441e-02\n",
       "                2.4224e-02 -1.0503e-01 -9.6918e-02  6.0880e-02  1.7780e-02\n",
       "               -7.4963e-03 -6.0305e-02 -2.7165e-02  6.7596e-02 -9.0809e-03\n",
       "                3.0578e-02 -4.8343e-02 -6.6212e-02  1.8453e-02  3.3076e-02\n",
       "               -5.9831e-02 -2.9084e-02 -5.6485e-03  8.1630e-02  3.0920e-02\n",
       "                 ...\n",
       "              \n",
       "              (30,13,.,.) = \n",
       "               -2.2676e-02 -8.1156e-03 -3.2434e-02 -4.2277e-02 -8.8996e-02\n",
       "                1.5018e-01 -7.3906e-02 -6.2445e-02 -5.2967e-02  1.5567e-02\n",
       "               -3.4239e-03 -1.0328e-01 -8.3196e-02 -1.1270e-01 -2.4603e-03\n",
       "               -1.2695e-01 -9.2834e-02 -1.6276e-01 -9.5663e-02  2.6213e-02\n",
       "                3.9594e-02  3.5510e-02 -1.0744e-01 -1.6748e-01 -6.0939e-02\n",
       "              \n",
       "              (30,14,.,.) = \n",
       "                1.1890e-03  3.4328e-03  4.8963e-03 -1.8820e-02 -1.7316e-02\n",
       "                1.8093e-02 -5.0741e-02 -3.5003e-02  2.1900e-02  3.9276e-02\n",
       "                3.9580e-02  5.7012e-02  1.0284e-02  1.9315e-02 -1.7490e-02\n",
       "                5.7026e-02  5.3412e-02 -2.1050e-02 -6.0048e-02 -1.7461e-02\n",
       "                8.0548e-02  4.2080e-02 -4.9083e-02  1.5203e-02  1.4205e-02\n",
       "              \n",
       "              (30,15,.,.) = \n",
       "               -7.9193e-03  8.7423e-02  3.6310e-02 -4.0973e-02  1.5151e-02\n",
       "               -4.7647e-02 -3.7383e-02 -2.7040e-02  1.9100e-02  3.0943e-02\n",
       "                8.8866e-03  3.1048e-02  6.0710e-03 -2.1493e-02 -1.1181e-03\n",
       "               -7.3120e-02  2.5338e-02 -9.0300e-03  5.8087e-02  7.9122e-02\n",
       "               -5.4747e-02 -4.2849e-02 -5.5322e-02  1.3645e-03  1.2730e-01\n",
       "                   ⋮ \n",
       "              \n",
       "              (31,0 ,.,.) = \n",
       "                2.0956e-02 -1.4084e-02 -3.6078e-02  1.9639e-02 -4.5119e-02\n",
       "               -6.6490e-02 -2.3200e-02 -4.3471e-02  4.2858e-02 -1.9344e-02\n",
       "               -6.9741e-02 -7.2172e-02  1.3285e-02 -3.0530e-02  4.1621e-02\n",
       "               -2.2855e-02 -7.4278e-03  4.0802e-02 -1.5260e-02 -5.0023e-02\n",
       "               -4.9523e-02 -1.6535e-02 -2.5182e-03 -5.5868e-03  4.0035e-02\n",
       "              \n",
       "              (31,1 ,.,.) = \n",
       "               -5.8629e-02 -5.0680e-02 -1.3250e-01 -1.1019e-01 -3.3656e-02\n",
       "               -4.9180e-02 -7.2052e-03  6.1107e-02  1.8862e-02  6.3004e-02\n",
       "               -1.6598e-02  9.4792e-03  1.0560e-01  1.3779e-01  4.2331e-02\n",
       "                1.4212e-01  5.6435e-02 -1.7299e-02  8.5808e-02  2.7325e-02\n",
       "                4.0998e-02  3.4895e-02 -5.7026e-02 -8.1741e-02 -7.7718e-02\n",
       "              \n",
       "              (31,2 ,.,.) = \n",
       "               -2.7470e-02  4.3163e-02 -3.4022e-02  6.1347e-02 -2.7628e-02\n",
       "               -1.0624e-02  5.2378e-03 -1.2702e-02 -4.0412e-02  5.2150e-02\n",
       "                7.6877e-02  7.5966e-02 -3.7217e-03 -5.7601e-03 -2.9030e-02\n",
       "               -2.7295e-02  5.5359e-02  1.1276e-02  8.2860e-02  1.3347e-02\n",
       "               -7.4463e-02 -7.7085e-02  2.6569e-02  4.2332e-02  5.4318e-02\n",
       "                 ...\n",
       "              \n",
       "              (31,13,.,.) = \n",
       "                1.5526e-03 -6.2073e-02 -2.3149e-02  4.0953e-03  2.4156e-02\n",
       "                3.6664e-02  9.0514e-02 -1.8510e-02 -4.8461e-02  6.6456e-03\n",
       "               -4.7498e-02  1.0313e-01  2.0386e-02 -9.5727e-02 -9.0312e-02\n",
       "                4.0894e-02 -1.1755e-02 -1.1210e-02  3.4369e-02  1.0347e-01\n",
       "                5.5477e-02  1.2943e-03 -4.3005e-02  3.3219e-02  5.2443e-02\n",
       "              \n",
       "              (31,14,.,.) = \n",
       "                1.7955e-02  5.9151e-02  1.2247e-01  1.1496e-01  1.3059e-02\n",
       "                1.1318e-01  1.7080e-02 -3.1348e-02  3.6005e-02  3.1040e-02\n",
       "               -8.1639e-02  4.0337e-02 -5.9094e-03  7.1192e-03  4.8137e-03\n",
       "               -1.4794e-01 -3.2340e-02  3.8613e-02  2.6906e-02  3.8812e-02\n",
       "                2.9614e-02  6.9498e-03 -1.0528e-02  5.1042e-03  1.8218e-02\n",
       "              \n",
       "              (31,15,.,.) = \n",
       "               -1.8106e-03  8.8558e-02  2.5194e-02 -4.3750e-03  3.1417e-03\n",
       "               -3.6177e-02 -8.6890e-02 -8.1717e-02 -4.6173e-02  2.4982e-02\n",
       "               -4.3872e-02 -1.0200e-01 -3.0494e-02 -1.2987e-02  7.3362e-03\n",
       "               -4.2872e-05  2.3449e-02  7.2800e-02 -6.9492e-02 -9.7279e-02\n",
       "                5.2367e-03 -6.1611e-02 -3.4151e-02  1.8065e-02 -7.1324e-02\n",
       "              [torch.FloatTensor of size 32x16x5x5]), ('layer2.0.bias', \n",
       "              1.00000e-02 *\n",
       "               -5.7584\n",
       "               -2.4762\n",
       "               -2.4036\n",
       "               -4.6642\n",
       "                0.0834\n",
       "                3.9278\n",
       "                2.4580\n",
       "               -1.9135\n",
       "               -1.1532\n",
       "               -3.3528\n",
       "               -0.0399\n",
       "               -4.8178\n",
       "               -5.4923\n",
       "               -1.4023\n",
       "                2.1197\n",
       "                2.2768\n",
       "                2.7389\n",
       "               -1.0586\n",
       "               -4.1538\n",
       "               -3.5466\n",
       "               -0.4864\n",
       "               -1.0472\n",
       "                1.2129\n",
       "                1.9162\n",
       "               -1.8341\n",
       "                3.1814\n",
       "                0.4797\n",
       "               -1.2266\n",
       "                1.9072\n",
       "               -6.7383\n",
       "                2.9027\n",
       "                0.2932\n",
       "              [torch.FloatTensor of size 32]), ('layer2.1.weight', \n",
       "               0.9537\n",
       "               1.0923\n",
       "               0.8622\n",
       "               0.8384\n",
       "               1.0369\n",
       "               0.9107\n",
       "               1.0291\n",
       "               0.8910\n",
       "               0.9480\n",
       "               0.5755\n",
       "               0.5847\n",
       "               0.9282\n",
       "               1.1160\n",
       "               0.7912\n",
       "               1.1061\n",
       "               0.4645\n",
       "               0.4926\n",
       "               1.1921\n",
       "               0.5492\n",
       "               0.8767\n",
       "               0.8662\n",
       "               0.6487\n",
       "               0.3487\n",
       "               0.9594\n",
       "               1.1352\n",
       "               0.7848\n",
       "               0.5013\n",
       "               0.4193\n",
       "               0.5537\n",
       "               1.1978\n",
       "               0.7854\n",
       "               1.0321\n",
       "              [torch.FloatTensor of size 32]), ('layer2.1.bias', \n",
       "              -0.0472\n",
       "              -0.0123\n",
       "              -0.0093\n",
       "              -0.0856\n",
       "              -0.0679\n",
       "              -0.1298\n",
       "              -0.0578\n",
       "              -0.0422\n",
       "              -0.0921\n",
       "              -0.1112\n",
       "              -0.0487\n",
       "              -0.0511\n",
       "              -0.1374\n",
       "               0.0294\n",
       "              -0.1277\n",
       "              -0.0629\n",
       "              -0.0578\n",
       "              -0.0865\n",
       "              -0.1151\n",
       "              -0.0454\n",
       "              -0.0455\n",
       "              -0.1508\n",
       "              -0.0393\n",
       "              -0.1168\n",
       "              -0.0911\n",
       "              -0.1423\n",
       "              -0.0701\n",
       "              -0.0979\n",
       "              -0.1349\n",
       "              -0.0889\n",
       "              -0.1377\n",
       "              -0.0585\n",
       "              [torch.FloatTensor of size 32]), ('layer2.1.running_mean', \n",
       "               0.0212\n",
       "               0.1781\n",
       "               0.4444\n",
       "              -0.0099\n",
       "               0.1501\n",
       "              -0.1626\n",
       "               0.1207\n",
       "              -0.0537\n",
       "              -0.0166\n",
       "              -0.0014\n",
       "               0.0366\n",
       "               0.0880\n",
       "              -0.3282\n",
       "               0.3529\n",
       "               0.1190\n",
       "              -0.0327\n",
       "               0.1196\n",
       "               0.0074\n",
       "              -0.0732\n",
       "              -0.0991\n",
       "               0.2102\n",
       "              -0.0554\n",
       "              -0.1019\n",
       "               0.1988\n",
       "              -0.2144\n",
       "              -0.1600\n",
       "               0.0893\n",
       "              -0.2526\n",
       "               0.0146\n",
       "              -0.1222\n",
       "               0.0003\n",
       "              -0.1194\n",
       "              [torch.FloatTensor of size 32]), ('layer2.1.running_var', \n",
       "               0.1502\n",
       "               0.1128\n",
       "               0.1234\n",
       "               0.1153\n",
       "               0.1163\n",
       "               0.1203\n",
       "               0.1527\n",
       "               0.1123\n",
       "               0.0872\n",
       "               0.1482\n",
       "               0.1929\n",
       "               0.1082\n",
       "               0.0709\n",
       "               0.0907\n",
       "               0.0933\n",
       "               0.1037\n",
       "               0.1552\n",
       "               0.0980\n",
       "               0.1447\n",
       "               0.1325\n",
       "               0.0880\n",
       "               0.1361\n",
       "               0.2036\n",
       "               0.1185\n",
       "               0.1418\n",
       "               0.1014\n",
       "               0.1356\n",
       "               0.1015\n",
       "               0.1054\n",
       "               0.0978\n",
       "               0.1155\n",
       "               0.0947\n",
       "              [torch.FloatTensor of size 32]), ('fc.weight', \n",
       "               1.6530e-03 -4.9434e-02 -4.6973e-02  ...  -1.0422e-02  3.8049e-02 -5.8998e-02\n",
       "               4.8030e-02  1.8779e-02  2.9703e-02  ...  -7.3076e-02 -3.6777e-02 -4.3162e-02\n",
       "               5.3329e-03 -2.3738e-02 -3.5388e-02  ...   3.8394e-02  8.8829e-02  1.3144e-02\n",
       "                              ...                   ⋱                   ...                \n",
       "               1.7572e-02  1.0560e-01  4.0851e-02  ...  -4.1990e-02 -7.7241e-02 -4.9235e-02\n",
       "              -1.6516e-03 -2.7082e-02  2.1556e-02  ...   1.3357e-02  1.5206e-02  4.8347e-02\n",
       "              -1.1894e-02 -3.0103e-02 -5.4926e-02  ...   2.5940e-02 -1.7088e-02 -1.1878e-02\n",
       "              [torch.FloatTensor of size 10x1568]), ('fc.bias', \n",
       "              1.00000e-02 *\n",
       "                0.8638\n",
       "                7.6558\n",
       "               -1.7293\n",
       "               -2.6890\n",
       "               -0.8516\n",
       "                1.1179\n",
       "                1.8579\n",
       "                1.2566\n",
       "                0.5925\n",
       "                1.9089\n",
       "              [torch.FloatTensor of size 10])])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
